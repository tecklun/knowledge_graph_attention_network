{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_kg_final(train, test, kg):\n",
    "    \"\"\"\n",
    "    Function to update kg_final by checking the input train.txt and test.txt, to identify the largest item index. \n",
    "    Then, on kg_final, reduce all entities with index > that identified earlier.\n",
    "    E.g. max(itemID) reduced from 100 to 50, then to kg_final:\n",
    "        all triplets with index 51 to 100 are removed\n",
    "        all indexes with values 101 and above are reduced by 50 (i.e. 101 -> 51, 102 -> 52)\n",
    "    Argument\n",
    "        train: train.txt:\n",
    "        test: test.txt:\n",
    "        kg: kg_final.txt\n",
    "    Return:\n",
    "        kg_final_chg.txt: Same as kg_final.txt, after removing all itemID not found in train/test.txt\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    # Train.txt\n",
    "    user_dict = dict()\n",
    "    inter_mat = list()\n",
    "    lines = open(train, 'r').readlines()\n",
    "    for l in lines:\n",
    "        tmps = l.strip()\n",
    "        inters = [int(i) for i in tmps.split(' ')]\n",
    "        u_id, pos_ids = inters[0], inters[1:]\n",
    "        pos_ids = list(set(pos_ids))\n",
    "        for i_id in pos_ids:\n",
    "            inter_mat.append([u_id, i_id])\n",
    "        if len(pos_ids) > 0:\n",
    "            user_dict[u_id] = pos_ids\n",
    "    train_data = np.array(inter_mat)\n",
    "    max_item_train = max(train_data[:,1])\n",
    "    \n",
    "    # Text.txt\n",
    "    user_dict = dict()\n",
    "    inter_mat = list()\n",
    "    lines = open(test, 'r').readlines()\n",
    "    for l in lines:\n",
    "        tmps = l.strip()\n",
    "        inters = [int(i) for i in tmps.split(' ')]\n",
    "        u_id, pos_ids = inters[0], inters[1:]\n",
    "        pos_ids = list(set(pos_ids))\n",
    "        for i_id in pos_ids:\n",
    "            inter_mat.append([u_id, i_id])\n",
    "        if len(pos_ids) > 0:\n",
    "            user_dict[u_id] = pos_ids\n",
    "    test_data = np.array(inter_mat)\n",
    "    max_item_test = max(test_data[:,1])\n",
    "    \n",
    "    # Check all indexes are valid\n",
    "    has_all_index_train = np.isin(np.arange(max_item_train), train_data[:,1])\n",
    "    miss_train_index = train_data[np.logical_not(has_all_index_train), 1]\n",
    "    \n",
    "    has_all_index_test = np.isin(np.arange(max_item_test), test_data[:,1])\n",
    "    miss_test_index = test_data[np.logical_not(has_all_index_test), 1]\n",
    "    \n",
    "    return max_item_train, max_item_test, has_all_index_train.all(), has_all_index_test.all(), miss_train_index, miss_test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 5023 but corresponding boolean dimension is 3490",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-51b0f5d546a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mupdate_kg_final\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'kg_final.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-36-db15ea398c47>\u001b[0m in \u001b[0;36mupdate_kg_final\u001b[1;34m(train, test, kg)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# Check all indexes are valid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mhas_all_index_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_item_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mmiss_train_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhas_all_index_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mhas_all_index_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_item_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 5023 but corresponding boolean dimension is 3490"
     ]
    }
   ],
   "source": [
    "update_kg_final('train.txt', 'test.txt', 'kg_final.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45537 []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train = 'train.txt'\n",
    "test = 'test.txt'\n",
    "    \n",
    "# Train.txt\n",
    "user_dict = dict()\n",
    "inter_mat = list()\n",
    "lines = open(train, 'r').readlines()\n",
    "for l in lines:\n",
    "    tmps = l.strip()\n",
    "    inters = [int(i) for i in tmps.split(' ')]\n",
    "    u_id, pos_ids = inters[0], inters[1:]\n",
    "    pos_ids = list(set(pos_ids))\n",
    "    for i_id in pos_ids:\n",
    "        inter_mat.append([u_id, i_id])\n",
    "    if len(pos_ids) > 0:\n",
    "        user_dict[u_id] = pos_ids\n",
    "train_data = np.array(inter_mat)\n",
    "max_item_train = max(train_data[:,1])\n",
    "\n",
    "# Text.txt\n",
    "user_dict = dict()\n",
    "inter_mat = list()\n",
    "lines = open(test, 'r').readlines()\n",
    "for l in lines:\n",
    "    tmps = l.strip()\n",
    "    inters = [int(i) for i in tmps.split(' ')]\n",
    "    u_id, pos_ids = inters[0], inters[1:]\n",
    "    pos_ids = list(set(pos_ids))\n",
    "    for i_id in pos_ids:\n",
    "        inter_mat.append([u_id, i_id])\n",
    "    if len(pos_ids) > 0:\n",
    "        user_dict[u_id] = pos_ids\n",
    "test_data = np.array(inter_mat)\n",
    "max_item_test = max(test_data[:,1])\n",
    "\n",
    "# Check all indexes are valid\n",
    "has_all_index_train = np.isin(np.arange(max_item_train), train_data[:,1])\n",
    "miss_train_index = np.arange(max_item_train)[np.logical_not(has_all_index_train)]\n",
    "print(max_item_train, miss_train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False,  True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isin(np.arange(max_item_train), train_data[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'range'> <class 'list'> range(1, 10) [] False\n"
     ]
    }
   ],
   "source": [
    "a = range(1,10)\n",
    "b = list(list())\n",
    "print(type(a), type(b), a, b, a==b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [1, 1],\n",
       "       [2, 2],\n",
       "       [3, 3],\n",
       "       [3, 4],\n",
       "       [4, 4]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "user_dict = dict()\n",
    "inter_mat = list()\n",
    "\n",
    "lines = open('train.txt', 'r').readlines()\n",
    "for l in lines:\n",
    "    tmps = l.strip()\n",
    "    inters = [int(i) for i in tmps.split(' ')]\n",
    "\n",
    "    u_id, pos_ids = inters[0], inters[1:]\n",
    "    pos_ids = list(set(pos_ids))\n",
    "\n",
    "    for i_id in pos_ids:\n",
    "        inter_mat.append([u_id, i_id])\n",
    "\n",
    "    if len(pos_ids) > 0:\n",
    "        user_dict[u_id] = pos_ids\n",
    "\n",
    "train_data = np.array(inter_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45537"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(train_data[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ratings(file_name):\n",
    "    import numpy as np\n",
    "    user_dict = dict()\n",
    "    inter_mat = list()\n",
    "\n",
    "    lines = open(file_name, 'r').readlines()\n",
    "    for l in lines:\n",
    "        tmps = l.strip()\n",
    "        inters = [int(i) for i in tmps.split(' ')]\n",
    "\n",
    "        u_id, pos_ids = inters[0], inters[1:]\n",
    "        pos_ids = list(set(pos_ids))\n",
    "\n",
    "        for i_id in pos_ids:\n",
    "            inter_mat.append([u_id, i_id])\n",
    "\n",
    "        if len(pos_ids) > 0:\n",
    "            user_dict[u_id] = pos_ids\n",
    "    return np.array(inter_mat), user_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kg(file_name):\n",
    "    import collections\n",
    "    import numpy as np\n",
    "    def _construct_kg(kg_np):\n",
    "        kg = collections.defaultdict(list)\n",
    "        rd = collections.defaultdict(list)\n",
    "\n",
    "        for head, relation, tail in kg_np:\n",
    "            kg[head].append((tail, relation))\n",
    "            rd[relation].append((head, tail))\n",
    "        return kg, rd\n",
    "\n",
    "    kg_np = np.loadtxt(file_name, dtype=np.int32)\n",
    "    kg_np = np.unique(kg_np, axis=0)\n",
    "\n",
    "    # self.n_relations = len(set(kg_np[:, 1]))\n",
    "    # self.n_entities = len(set(kg_np[:, 0]) | set(kg_np[:, 2]))\n",
    "    n_relations = max(kg_np[:, 1]) + 1\n",
    "    n_entities = max(max(kg_np[:, 0]), max(kg_np[:, 2])) + 1\n",
    "    n_triples = len(kg_np)\n",
    "\n",
    "    kg_dict, relation_dict = _construct_kg(kg_np)\n",
    "\n",
    "    return kg_np, kg_dict, relation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2)\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [0 3]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [3 3]\n",
      " [4 1]\n",
      " [4 2]\n",
      " [4 3]]\n",
      "{0: [0, 1, 2, 3], 1: [1], 2: [2], 3: [3], 4: [1, 2, 3]}\n"
     ]
    }
   ],
   "source": [
    "inter_mat, user_dict = load_ratings('E:/GitHub/knowledge_graph_attention_network/Data/own_data/own_train.txt')\n",
    "print(inter_mat.shape)\n",
    "print(inter_mat)\n",
    "print(user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_np, kg_dict, relation_dict = load_kg('E:/GitHub/knowledge_graph_attention_network/Data/own_data/own_kg.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 3 1]\n",
      " [0 4 2]]\n",
      "defaultdict(<class 'list'>, {0: [(1, 3), (2, 4)]})\n",
      "defaultdict(<class 'list'>, {3: [(0, 1)], 4: [(0, 2)]})\n"
     ]
    }
   ],
   "source": [
    "print(kg_np)\n",
    "print(kg_dict)\n",
    "print(relation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91455"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "45537+45918"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
